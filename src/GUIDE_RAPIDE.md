# ğŸ¯ GUIDE RAPIDE - Application de Prospection FusionnÃ©e

## âœ¨ Ce qui a Ã©tÃ© crÃ©Ã©

Un **nouveau dossier `src`** qui fusionne les deux sources existantes :
- âœ… **src_1** (Pages Jaunes + BDNB) 
- âœ… **src_2** (OSM + API Entreprises)

**Aucun code des sources originales n'a Ã©tÃ© modifiÃ© ou supprimÃ©.**

## ğŸ“ Structure du projet

```
JE/
â”œâ”€â”€ src_1/              # Source originale 1 (inchangÃ©e)
â”œâ”€â”€ src_2/              # Source originale 2 (inchangÃ©e)
â””â”€â”€ src/                # ğŸ†• NOUVEAU - Fusion des deux sources
    â”œâ”€â”€ main.py         # ğŸš€ Lancez ceci !
    â”œâ”€â”€ ui_merged.py    # Interface graphique
    â”œâ”€â”€ enrichment.py   # Fusion des donnÃ©es
    â”œâ”€â”€ export_data.py  # Export CSV + Carte
    â”œâ”€â”€ README.md       # Documentation complÃ¨te
    â”œâ”€â”€ requirements.txt
    â””â”€â”€ run.sh          # Script de dÃ©marrage
```

## ğŸš€ DÃ©marrage rapide

### Option 1 : Script automatique (recommandÃ©)

```bash
cd /home/tim/Documents/Projet/JE/src
./run.sh
```

### Option 2 : Manuel

```bash
cd /home/tim/Documents/Projet/JE/src

# Installer les dÃ©pendances (premiÃ¨re fois)
pip install -r requirements.txt

# Lancer l'application
python main.py
```

## ğŸ¨ Interface utilisateur

L'application s'ouvre avec une interface graphique moderne basÃ©e sur **src_2** :

1. **Adresse** : Point de dÃ©part de la recherche  
   Exemple : `10 Rue de la Paix, 75002 Paris`

2. **Rayon** : Distance de recherche en km  
   Exemple : `0.5` (500 mÃ¨tres)

3. **Dossier** : Nom pour sauvegarder les rÃ©sultats  
   Exemple : `ma_prospection`

4. **Lancer** : DÃ©marre la prospection

## ğŸ“Š RÃ©sultats gÃ©nÃ©rÃ©s

Les rÃ©sultats sont sauvegardÃ©s dans `output/[nom_dossier]/` :

### ğŸ“„ resultats.csv
Tableur Excel/CSV avec **toutes les donnÃ©es enrichies** :
- Informations gÃ©nÃ©rales (nom, adresse, coordonnÃ©es, distance)
- **Source 1 (Pages Jaunes)** : tÃ©lÃ©phone, titre
- **Source 1 (BDNB)** : annÃ©e construction, classe DPE
- **Source 2 (OSM)** : catÃ©gorie, tÃ©lÃ©phones, emails, sites web
- **Source 2 (API)** : SIREN, SIRET, NAF, dirigeants
- **Source 2 (BÃ¢timent)** : surface toiture, parking

### ğŸ—ºï¸ carte.html
Carte interactive Leaflet avec :
- Fond satellite ou plan au choix
- Cercle de recherche visible
- Marqueurs clusterisÃ©s
- Popups dÃ©taillÃ©es avec badges colorÃ©s par source
- **Double-cliquez** pour ouvrir dans votre navigateur

### ğŸ“ log.txt
Journal d'exÃ©cution avec tous les dÃ©tails

## ğŸ”„ Workflow de l'application

```
1. ğŸ“ GÃ©ocodage de l'adresse initiale
   â””â”€> Obtention des coordonnÃ©es GPS

2. ğŸ” Recherche des entreprises (Overpass OSM)
   â””â”€> Liste des entreprises dans le rayon

3. ğŸ”„ Pour chaque entreprise :
   â”œâ”€> GÃ©ocodage de son adresse (BAN)
   â”œâ”€> Enrichissement Source 2 (API + OSM) âš¡ Rapide
   â””â”€> Enrichissement Source 1 (PJ + BDNB) ğŸ¢ Plus lent

4. ğŸ’¾ Export des rÃ©sultats
   â”œâ”€> CSV avec toutes les colonnes
   â””â”€> Carte HTML interactive
```

## ğŸ’¡ Avantages de cette fusion

| Source 1 (src_1) | Source 2 (src_2) | ğŸ†• Fusion (src) |
|------------------|------------------|-----------------|
| TÃ©lÃ©phone PJ âœ… | TÃ©lÃ©phones OSM âœ… | **LES DEUX** âœ…âœ… |
| Titre PJ âœ… | - | **Titre PJ** âœ… |
| AnnÃ©e construction âœ… | AnnÃ©e bÃ¢timent âœ… | **LES DEUX** âœ…âœ… |
| Classe DPE âœ… | - | **DPE** âœ… |
| - | Emails âœ… | **Emails** âœ… |
| - | Sites web âœ… | **Sites web** âœ… |
| - | SIREN/SIRET âœ… | **SIREN/SIRET** âœ… |
| - | Dirigeants âœ… | **Dirigeants** âœ… |
| - | Surface toiture âœ… | **Surface toiture** âœ… |

**RÃ©sultat : Maximum d'informations pour chaque entreprise !**

## âš™ï¸ PrÃ©requis systÃ¨me

### Obligatoire
- Python 3.8+
- ChromeDriver (pour le scraping Pages Jaunes)

### Installation ChromeDriver

**Ubuntu/Debian :**
```bash
sudo apt-get update
sudo apt-get install chromium-chromedriver
```

**macOS :**
```bash
brew install chromedriver
```

**Windows :**
TÃ©lÃ©chargez depuis https://chromedriver.chromium.org/

## ğŸ“¦ DÃ©pendances Python

Toutes listÃ©es dans `requirements.txt` :
- `requests` : Appels HTTP
- `beautifulsoup4` : Parsing HTML
- `selenium` : Scraping dynamique
- `PySide6` : Interface graphique
- `overpy` : API Overpass OSM
- `geopy` : GÃ©ocodage
- `pyproj` : Calculs gÃ©ographiques

## âš ï¸ Notes importantes

1. **Scraping Pages Jaunes** : Peut Ãªtre lent (dÃ©lais anti-dÃ©tection)
2. **Rate limits** : BDNB limitÃ© Ã  120 req/min
3. **ParallÃ©lisation** : 2 workers maximum pour ne pas surcharger
4. **Temps d'exÃ©cution** : ~2-3 min pour 20 entreprises

## ğŸ› DÃ©pannage

### Erreur "ChromeDriver not found"
```bash
# VÃ©rifiez l'installation
which chromedriver

# Si manquant, installez-le
sudo apt-get install chromium-chromedriver
```

### Erreur "Module not found"
```bash
# RÃ©installez les dÃ©pendances
pip install -r requirements.txt
```

### Scraping PJ bloquÃ©
- RÃ©duisez le nombre d'entreprises
- Augmentez les dÃ©lais dans `scrapper.py`
- Utilisez uniquement la source 2 temporairement

## ğŸ“ Support

Pour toute question ou amÃ©lioration :
1. Consultez `src/README.md` (documentation complÃ¨te)
2. VÃ©rifiez les logs dans `output/[dossier]/log.txt`
3. Les sources originales `src_1` et `src_2` restent intactes et utilisables

## ğŸ“ Pour aller plus loin

- Modifiez `enrichment.py` pour ajouter d'autres sources
- Personnalisez `export_data.py` pour changer le format CSV
- Adaptez `ui_merged.py` pour modifier l'interface
- Consultez les logs pour comprendre le comportement

---

**Bon courage avec votre prospection ! ğŸš€**
